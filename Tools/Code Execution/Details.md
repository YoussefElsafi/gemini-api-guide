--------------------------------------------------------------------------------

                      Gemini API: Code Execution Feature

--------------------------------------------------------------------------------

OVERVIEW:

The Gemini API's code execution feature empowers the model to generate and run Python code.  It's an iterative process: the model learns from the code's output to refine its response until a final answer is reached. This is particularly useful for tasks requiring code-based reasoning, like mathematical calculations or text processing.  It behaves like a tool (similar to function calling) that the model chooses to use when appropriate.

HOW IT WORKS:

1.  **Enablement:** You must explicitly enable code execution for the model.  In the Gemini API, you add it as a tool. In AI Studio, it's an option in the right panel under "Tools".

2.  **Code Generation & Execution:**  When the model determines code execution is necessary, it generates Python code.  This code is then executed in a secure environment.

3.  **Iterative Learning:** The model analyzes the output of the executed code. If the output isn't satisfactory (e.g., an error occurs, or the result doesn't fully answer the prompt), the model may regenerate and re-execute the code, up to 5 times.

4.  **Output:** The final output can include:
    *   Textual summaries generated by the model.
    *   The generated Python code itself.
    *   The output produced by the executed code.
    *   Matplotlib-generated graphs (starting with Gemini 2.0 Flash).

SUPPORTED LIBRARIES:

The code execution environment includes these pre-installed Python libraries:

*   altair
*   chess
*   cv2
*   matplotlib (for graph rendering)
*   mpmath
*   numpy
*   pandas
*   pdfminer
*   reportlab
*   seaborn
*   sklearn
*   statsmodels
*   striprtf
*   sympy
*   tabulate

*   You cannot install additional libraries.*

INPUT/OUTPUT (I/O) CAPABILITIES (Starting with Gemini 2.0 Flash):

*   **File Input:** You can upload files (e.g., CSV, text files) for the model to analyze. Supported file types include .png, .jpeg, .csv, .xml, .cpp, .java, .py, .js, and .ts.

*   **Graph Output:**  The model can generate graphs using Matplotlib as part of its response.

I/O TECHNICAL DETAILS:

*   **Maximum Runtime:** The code execution environment has a 30-second runtime limit.
*   **Error Handling:** If the code generates an error, the model attempts to regenerate the code (up to 5 times).
*   **File Size Limits:** The maximum file input size is limited by the model's token window (approximately 2MB for text files, or 1 million tokens, in AI Studio with Gemini Flash 2.0).
*   **Supported Models:** All gemini 2.0 models, but for bidirectional communication, flash experimental models are needed.
*  **Plotting Libraries:** Only Matplotlib.
*   **Multi-tool Use:** Not available for Single turn, available for Bidirectional (Multimodal Live API).

BILLING:

*   **No Extra Charge for Enabling:** There's no separate fee to enable the code execution feature itself.

*   **Token-Based Billing:** You are charged for input and output tokens at the standard rate for the Gemini model you're using.

*   **Token Breakdown:**
    *   **Input Tokens:** Include your initial prompt.
    *   **Output Tokens:** Include the model's generated summary, the generated code, and the code execution output.

*    **Intermediate Tokens (Starting Feb 24, 2025):**
    *   When code execution is used, the original prompt, generated code, and execution results are considered *intermediate tokens* and are billed as *input* tokens.
    *   The final summary, generated code, and execution results returned to you are billed as *output* tokens.
    *   The API response will include an "intermediate token count" to clarify billing.

LIMITATIONS:

*   **Code-Only Output:** The model can only generate and execute code. It can't directly return other file types (except for Matplotlib graphs).

*   **Potential Regressions:**  Enabling code execution might, in some cases, negatively impact other aspects of the model's output (e.g., creative writing).

*   **Model Variability:** The effectiveness of code execution can vary between different Gemini models.

INSTRUCTIVE CODE SNIPPETS (Illustrative, not complete examples):

*   **Enabling Code Execution:**
    ```
    tools=[types.Tool(code_execution=types.ToolCodeExecution)]
    ```
    This shows how to include `code_execution` as a tool in the configuration.

*   **Chat Usage**
     The system can also be used in a chat.
    ```
    model = genai.GenerativeModel(model_name='gemini-2.0-flash-exp', tools='code_execution')
    ```
    This snippet shows how to enable code execution in the chat.

KEY TAKEAWAYS:

*   Code execution is a powerful tool for tasks requiring computational or logical reasoning.
*   It's integrated directly into the Gemini API and AI Studio.
*   Understand the billing implications related to input, output, and intermediate tokens.
*   Be mindful of the limitations, particularly the code-only output and potential model-specific variations.